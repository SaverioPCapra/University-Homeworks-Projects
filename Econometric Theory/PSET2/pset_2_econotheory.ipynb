{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSET 2 - Econometric Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I import the Python modules (or libraries) that I'll need to solve the problems\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I read the csv of the dataset and I assign it to a variable\n",
    "data = pd.read_csv(\"tracking.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data[[\"tracking\", \"scoreendfirstgrade\", \"schoolid\"]].groupby([\"schoolid\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tracking</th>\n",
       "      <th>scoreendfirstgrade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schoolid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.184369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.178371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.068224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.024504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.757769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tracking  scoreendfirstgrade\n",
       "schoolid                              \n",
       "430            1.0           -0.184369\n",
       "432            1.0           -0.178371\n",
       "436            1.0           -0.068224\n",
       "443            0.0           -0.024504\n",
       "451            0.0           -0.757769"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_mean = grouped_data.groupby([\"tracking\"]).mean()\n",
    "ATE_estimation = tracking_mean.iloc[1]-tracking_mean.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scoreendfirstgrade    0.133913\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATE_estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this simple estimate it seems that tracking has a positive effect on end of first grade scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation for the `stats-ttest_ind` function: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the outcome of our Welch's test: \n",
      " 1) T-statistic: 1.678443563442577 \n",
      " 2) P-Value 0.09622272798001359\n",
      "Finding is robust at 10% level randomization inference\n"
     ]
    }
   ],
   "source": [
    "# I calculate the T-test for the means of two independent samples of scores.\n",
    "# This test assumes that the populations have identical variances by default, but I set equal_var to False in order to use the Welch's t-test and drop this assumption.\n",
    "observed_t = stats.ttest_ind(grouped_data[grouped_data['tracking'] == 1]['scoreendfirstgrade'],\n",
    "                            grouped_data[grouped_data['tracking'] == 0]['scoreendfirstgrade'], equal_var = False)\n",
    "# I print the output of the test\n",
    "print(f\"This is the outcome of our Welch's test: \\n 1) T-statistic: {observed_t.statistic} \\n 2) P-Value {observed_t.pvalue}\")\n",
    "\n",
    "# Generate permutations (I chose 10000 as an arbitrary number, no specific reason for it)\n",
    "num_permutations = 10000\n",
    "# Here I store the outcome of each simulation\n",
    "permutation_t_stats = []\n",
    "\n",
    "# This is a for-loop that repeats for 10000 times\n",
    "for i in range(num_permutations):\n",
    "    # Creates a permuted version of the DataFrame by randomly shuffling the rows without replacement\n",
    "    permuted_df = grouped_data.sample(frac=1/4, replace=False)\n",
    "    # Calculates the t-statistic for the permuted data\n",
    "    permutation_t = stats.ttest_ind(permuted_df[permuted_df['tracking'] == 1]['scoreendfirstgrade'],\n",
    "                                   permuted_df[permuted_df['tracking'] == 0]['scoreendfirstgrade']).statistic\n",
    "    \n",
    "    permutation_t_stats.append(permutation_t)\n",
    "\n",
    "# Determine critical value\n",
    "critical_value = np.percentile(permutation_t_stats, 10)\n",
    "\n",
    "# Compare observed statistic to critical value\n",
    "if abs(observed_t.statistic) > critical_value:\n",
    "    print(\"Finding is robust at 10% level randomization inference\")\n",
    "else:\n",
    "    print(\"Finding is not robust at 10% level randomization inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.30192626054885086"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critical_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
